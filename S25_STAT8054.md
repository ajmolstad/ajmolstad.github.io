---
layout: defaultCourse
title: STAT8054
permalink: /S25_STAT8054/
---

# STAT 8054: Advanced Statistical Computing
**Instructor.** Aaron J. Molstad (*amolstad@umn.edu*)  
**Office hours.** Monday 3:00 - 4:00PM and Wednesday 9:00 - 10:00AM in Ford Hall 384

**Syllabus.** [[pdf](https://canvas.umn.edu/files/49831537/download?download_frd=1)]   
**Lecture.** Monday, Wednesday, Friday at 12:20 - 1:10PM in Ford Hall 170 

Note that you must be logged into your UMN Canvas account to access course materials.   

----------------------

|| **Lecture** ||  **Topics** ||  
|| 1.1 (1/22)  || Course overview [[slides](https://canvas.umn.edu/files/49831522/download?download_frd=1)] ||   
|| 1.2 (1/24)  || Fundamentals of numerical linear algebra [[slides](https://canvas.umn.edu/files/49893294/download?download_frd=1)]||    
|| 1.3 (1/27)  || Computational complexity, matrix decompositions [[slides](https://canvas.umn.edu/files/49962875/download?download_frd=1)] ||  

Lecture 1 [[notes](https://canvas.umn.edu/files/50044826/download?download_frd=1)]

----------------------

|| 2.1 (1/29)  || Unconstrained optimization overview [[slides](https://canvas.umn.edu/files/50039527/download?download_frd=1)] ||   
|| 2.2 (1/31)  || Optimality conditions, convexity [[slides](https://canvas.umn.edu/files/50104516/download?download_frd=1)] ||   
|| 2.3 (2/3)  || Quasiconvexity, strong convexity, L-smoothness [[slides](https://canvas.umn.edu/files/50179163/download?download_frd=1) || 

Lecture 2 [[notes](https://canvas.umn.edu/files/50330601/download?download_frd=1)]

-----------------------

|| 3.1 (2/5)  || Steepest descent, gradient descent [[slides](https://canvas.umn.edu/files/50261601/download?download_frd=1)] ||  
|| 3.2 (2/7) || Example, accelerated gradient descent [[slides](https://canvas.umn.edu/files/50330595/download?download_frd=1)] ||  
|| 3.3 (2/10) || Newton's method [[slides](https://canvas.umn.edu/files/50414285/download?download_frd=1)] || 

Lecture 3 [[notes](https://canvas.umn.edu/files/50528849/download?download_frd=1)]


-----------------------


|| 4.1 (2/12) || Majorize-minimize principle [[slides](https://canvas.umn.edu/files/50495130/download?download_frd=1)] ||  
|| 4.2 (2/14) || Expectation-maximization algorithm [[slides](https://canvas.umn.edu/files/50564479/download?download_frd=1)] ||  
|| 4.3 (2/17) || Proximal gradient descent [[slides](https://canvas.umn.edu/files/50650734/download?download_frd=1)] ||  

